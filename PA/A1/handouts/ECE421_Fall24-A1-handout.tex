\documentclass{article}

%Linux command prompt showing package
\usepackage{listings,menukeys}

%Page format
\usepackage{pdfpages,fancyhdr}
\usepackage[margin=1in]{geometry}

%Math packages and custom commands
\usepackage{algpseudocode,amsmath,framed,tikz,sans,mathtools,amsthm,enumitem,amssymb,dsfont,tabularray,fancyvrb}
\usepackage[hidelinks]{hyperref}
\usepackage[table,xcdraw]{xcolor}
%\usepackage[labelformat=empty]{caption}
\usepackage[utf8]{inputenc}
\usetikzlibrary{arrows.meta}
\usepackage[TABcline]{tabstackengine}
\TABstackMath


\usepackage[table]{xcolor}
\usepackage{collcell}
\usepackage{hhline}
\usepackage{pgf}
\usepackage{multirow}

\def\colorModel{hsb}
\newcommand\ColCell[1]{
	\pgfmathparse{#1<50?1:0}  %Threshold for changing the font color into the cells
	\ifnum\pgfmathresult=0\relax\color{white}\fi
	\pgfmathsetmacro\compA{0}      %Component R or H
	\pgfmathsetmacro\compB{#1/100} %Component G or S
	\pgfmathsetmacro\compC{1}      %Component B or B
	\edef\x{\noexpand\centering\noexpand\cellcolor[\colorModel]{\compA,\compB,\compC}}\x #1
} 
\newcolumntype{E}{>{\collectcell\ColCell}m{0.4cm}<{\endcollectcell}}  %Cell width
\newcommand*\rot{\rotatebox{90}}

%Course Info
\newcommand{\coursenumber}{ECE421}
\newcommand{\coursename}{\coursenumber: Introduction to Machine Learning}
\newcommand{\courseyear}{2024}
\newcommand{\coursesemester}{Fall}
\newcommand{\coursefullname}{\coursename~---~\coursesemester~\courseyear}
%Handout Info
\newcommand{\haname}{Due Date: Thursday, September 26, 11:59 PM}
\newcommand{\hatypeandnun}{Assignment 1: Pocket Algorithm and Linear Regression}


\DeclareMathOperator{\R}{\mathbb{R}}
\newcommand{\probP}{\mathds{P}}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\Cov}{\text{Cov}}
\renewcommand{\arraystretch}{1.3}
\newcommand{\norm}[2][2]{\| #2\|_{#1}}

\newcommand{\notp}{\neg p}
\newcommand{\notq}{\neg q}
\newcommand{\notr}{\neg r}
\newcommand{\notP}{\neg P}
\newcommand{\notQ}{\neg Q}

\newcommand{\con}{\wedge}
\newcommand{\dis}{\vee}
\newcommand{\false}{\text{F}}
\newcommand{\terue}{\text{T}}

% verbatim
\DefineShortVerb{\|}
\SaveVerb{py}|Python|
\SaveVerb{num}|NumPy|
\SaveVerb{sci}|scikit-learn|
\SaveVerb{tp1}|test_Part1()|
\SaveVerb{tp2}|test_Part2()|

\definecolor{shadecolor}{gray}{0.9}

\theoremstyle{definition}
\newtheorem*{answer}{Answer}
\newcommand{\note}[1]{\noindent{[\textbf{NOTE:} #1]}}
\newcommand{\hint}[1]{\noindent{[\textbf{HINT:} #1]}}
\newcommand{\recall}[1]{\noindent{[\textbf{RECALL:} #1]}}
\newcommand{\expect}[1]{\noindent{[\textbf{What we expect:} #1]}}
\newcommand{\mysolution}[1]{\noindent{\begin{shaded}\textbf{Your Solution:}\ #1 \end{shaded}}}

\newlist{question}{enumerate}{3}
\setlist[question, 1]{label=\Large \textbf{Q\arabic{questioni}.}, leftmargin=\parindent, rightmargin=10pt}
\setlist[question, 2]{label=\large \textbf{\arabic{questioni}.\alph{questionii}.}, leftmargin=15pt, rightmargin=15pt}
\setlist[question, 3]{label=\textbf{\arabic{questioni}.\alph{questionii}.\kern1.5pt\roman{questioniii}.},	leftmargin=30pt, rightmargin=30pt}

\newlist{todolist}{itemize}{2}
\setlist[todolist]{label=$\square$}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\done}{\rlap{$\square$}{\raisebox{2pt}{\large\hspace{1pt}\cmark}}%
	\hspace{-2.5pt}}
\newcommand{\wontfix}{\rlap{$\square$}{\large\hspace{1pt}\xmark}}


\title{\vspace{-2.5cm}\textbf{\coursefullname}\\\hatypeandnun\\\haname}
\date{}

%\chead{}
\rhead{\haname}
\lfoot{}
\cfoot{\coursenumber~\coursesemester~\courseyear~---~\hatypeandnun}
\rfoot{\thepage}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}
\pagestyle{fancy}
\setlength{\parindent}{0pt}

% NOTE(joe): This environment is credit @pnpo (https://tex.stackexchange.com/a/218450)
\lstnewenvironment{algorithm}[1][] %defines the algorithm listing environment
{   
	\lstset{ %this is the stype
		mathescape=true,
		frame=tB,
		numbers=left, 
		numberstyle=\tiny,
		basicstyle=\rmfamily\scriptsize, 
		keywordstyle=\color{black}\bfseries,
		keywords={,procedure, div, mod, for, to, input, output, return, datatype, function, in, if, else, foreach, while, begin, end, } %add the keywords you want, or load a language as Rubens explains in his comment above.
		numbers=left,
		xleftmargin=.04\textwidth,
		#1 % this is to add specific settings to an usage of this environment (for instnce, the caption and referable label)
	}
}
{}

\begin{document}

\maketitle
\vspace*{-2cm}
\section*{Objectives}
In this assignment, you will be implementing the following algorithms: \textbf{Pocket Algorithm} and \textbf{Linear Regression}; using two different methods of coding approaches. 
\begin{itemize}
	\item In the first approach, you will implement these algorithms using \UseVerb{py} and functions in the \UseVerb{num} library only.
	\item In the second approach, you will use \UseVerb{sci} to gauge how well your initial implementation using \UseVerb{num} functions fares in comparison to off-the-shelf modules available in \UseVerb{sci}.
	\item You will also be asked to answer several questions related to your implementations.
\end{itemize}
To avoid any potential installation issue, you are encouraged to develop your solution using Google Colab notebooks.
\section*{Requirements}
In your implementations, please use the function prototype provided (\textit{i.e.} name of the function, inputs and
outputs) in the detailed instructions presented in the remainder of this document. We will be testing your
code using a test function that which evokes the provided function prototype. If our testing file is unable to
recognize the function prototype you have implemented, you can lose significant portion of your marks. In
the  assignment folder, the following files are included in the \verb|starter_code| folder:
\begin{itemize}
	\item \verb|PerceptronImp.py|
	\item \verb|LinearRegressionImp.py|
\end{itemize}
These  files contain the test function and an outline of the functions that you will be implementing. You also
need  to submit a separate \verb|PA1_qa.pdf| file that answer questions related to your implementations.
\section{Pocket Algorithm}
In the \verb|PerceptronImp.py| file, you will implement the Pocket Algorithm to classify two different classes
in the \verb|IRIS| dataset. You do not need to download the dataset as it is included in the \verb|scikit-learn|
library. For evaluation, we provide you the test function \verb|test_Part1()|. This function loads the \verb|IRIS| dataset,
runs your implementation and outputs the confusion matrix on the test set (for each coding approach).
Follow the below instructions to get started.\\
\note{keep the function \UseVerb{tp1} as it is in your submission.}
\subsection{Pocket Algorithm Using \UseVerb{num}}\label{sec1.a}
You will be implementing the Pocket Algorithm using the \UseVerb{num} library functions in the \verb|PerceptronImp.py|
file. You will be computing parameters of a linear plane that best separates input features belonging to two
classes. Specifically, you will be implementing the three functions listed below. For more instructions and hints, see the comments in the \verb|PerceptronImp.py|
file.
\begin{itemize}
	\item{\verb|fit_Perceptron(X_train, y_train)|\\\textbf{Function implementation considerations:}
			This function computes the parameters \verb|w| of a linear plane which separates the input features
			from the training set into two classes specified by the training dataset. As the pocket algorithm
			is used, you will set the maximum number of epochs (the maximum number of passes over the
			training data) to 5000. Useful functions in \verb|NumPy| for implementing this function are: 
			\begin{itemize}
				\item \verb|zeros|: for initializing the weight vector with 0s.
				\item \verb|shape|: for identifying the number of rows and columns in a matrix.
				\item \verb|hstack|: for adding an additional column to the front of the original input matrix.
				\item \verb|ones|: for setting the first column of the input feature matrix to 1.
				\item \verb|dot|: for taking the dot product of two vectors of the same size.
			\end{itemize}
			You will also use the function \verb|errorPer|
			that you will implement next to compute the average number of misclassifications for the plane
			you are currently considering with respect to the training dataset.}
		\item{\verb|errorPer(X_train, y_train, w)|\\\textbf{Function implementation considerations:}
			This function finds the ratio of missclassified points. Note that a point on the hyperplane must be considered as a missclasification.}
		\item{\verb|confMatrix(X_train, y_train, w)|\\\textbf{Function implementation considerations:}
			This function will populate a two-by-two matrix. Using the zero-index, the (0, 0) position represents
			a count of the total number of points correctly classified to be class -1 (True Negative).
			The (0, 1) position contains a count of total number of points that are in class -1 but are
			classified to be class +1 by the classifier (False Positive). The (1, 0) position contains a count
			of total number of points that are in class +1 but are classified to be class -1 by the classifier
			(False Negative). The (1, 1) position represents a count of the total number of points correctly
			classified to be class +1 (True Positive). Refer to the table below.
			\begin{center}
				\begin{tabular}{ cccc } 
					& & \multicolumn{2}{c}{PREDICTION} \\ 
					\multirow{4}{*}{\rotatebox{90}{ACTUAL}} & & -1 & +1 \\ %\cline{2-4}
					& -1 & \cellcolor{blue!25}{True Negative} & \cellcolor{red!25}{False Positive}  \\% \cline{2-4}
					& +1 & \cellcolor{red!25}{False Negative} & \cellcolor{blue!25}{True Positive}  \\ %\cline{2-4}
				\end{tabular}
			\end{center}
			You may find the function \verb|pred| implemented in \verb|perceptronImp.py| useful.}
\end{itemize}

The following is the mark breakdown for Part~\ref{sec1.a}:
\begin{enumerate}[label=(\roman*)]
	\item Test file successfully runs all four implemented functions: 8 marks
	\item Outputs of all four functions are close to the expected output: 12 marks
	\item Code content is organized well and annotated with useful comments: 10 marks
\end{enumerate}
\subsection{Pocket Algorithm Using \UseVerb{sci}} \label{part1.2}
In this part, you will use the \verb|scikit-learn| library to train the binary linear classification model. You will
then compare the performance of your implementation in Part~\ref{sec1.a} with the one available in the \verb|scikit-learn|
library. You will implement one function in this part in the \verb|PerceptronImp.py| file. You can refer to the Perceptron class and function reference by scikit-learn, available  \href{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html}{here}, to familiarize yourself with the implementation of this linear model and its parameters. Specifically, you will be implementing the function listed below. For more instructions and hints, see the comments in the \verb|PerceptronImp.py|
file.
\begin{itemize}
	\item{\verb|(X_train, X_test, y_train, y_test)|\\\textbf{Function implementation considerations:}
		\verb|Perceptron| and \verb|confusion_matrix| functions imported from \verb|sklearn.linear_model| and
		\verb|sklearn.metrics| will be utilized to fit the linear classifer using the Perceptron learning
		algorithm and evaluate the performance of this algorithm. First, initiate an object of the \verb|Perceptron| type. Then, run the \verb|fit|
		function to train the classifier. Next, use the \verb|predict| function to perform predictions using
		the trained algorithm. Finally, use the \verb|confusion_matrix| function to identify how
		many points have been classified correctly and incorrectly in the test dataset. \textbf{Refer to the
		 questions below} in order to set the parameters for your \verb|Perceptron| model.} 
\end{itemize}

\textbf{Answer the following question(s)}. Write and save your answers in a separate \verb|PA1_qa.pdf| file. Remember
to submit this file together with your code.
\begin{enumerate}[label=\ref{part1.2}.\alph*)]
	\item Refer to the documentation, what is the functionality of the \verb|tol| parameter in the \verb|Perceptron| class?	(2 marks)
	\item If we set \verb|max_iter=5000| and \verb|tol=1e-3| (the rest as default), does this guarantee that the algorithm will pass over the training data 5000 times? If not, ensure that the algorithm will pass over the training data 5000 times? (2 marks)
	\item How can we set the weights of the model to a certain value? (2 marks)
	\item How close is the performance (through confusion matrix) of your \verb|NumPy| implementation in comparison to the existing modules in the \verb|scikit-learn| library? (2 marks)
\end{enumerate}
The following is the mark breakdown for Part~\ref{part1.2}:
\begin{enumerate}[label=(\roman*)]
	\item Test file successfully runs implemented function: 4 marks
	\item Output is close to the expected output from the test file: 5 marks
	\item Code content is organized well and annotated with comments: 3 marks
	\item Questions are answered correctly: 8 marks
\end{enumerate}
%\newpage
\section{Linear Regression}
In the \verb|LinearRegressionImp.py| file, you will implement the Linear Regression algorithm and test its
performance using the diabetes dataset. You do not need to download the dataset as it is included in the
\verb|scikit-learn| library. For evaluation, we provide you the test function \verb|test_Part2()|. This function loads the diabetes dataset, runs your implementation
and outputs the mean-squared-error on the test set (for each coding approach). Follow the below instructions
to get started.\\\note{keep the function \UseVerb{tp2} as it is in your submission.}
\subsection{Linear Regression Using \UseVerb{num}} \label{part2.1}
You will be implementing in \verb|LinearRegressionImp.py| the exact computation of the solution for linear
regression using the \verb|NumPy| library functions via the least squares method. You will be computing the
parameters of a linear plane that best fits the training dataset. Specifically, you will be implementing the two
functions which are detailed in the following. For more instructions and hints, see the comments in the \verb|LinearRegressionImp.py|
file.
\begin{itemize}
	\item{\verb|fit_LinRegr(X_train, y_train)|\\\textbf{Function implementation considerations:} This function computes the parameters \verb|w| of a linear plane which best fits the training dataset. Useful functions in \verb|NumPy| for implementing this function are: 
		\begin{itemize}
			\item \verb|shape|: for identifying the number of rows and columns in a matrix.
			\item \verb|hstack|: for adding an additional column to the front of the original input matrix.
			\item \verb|ones|: for setting the first column of the input feature matrix to 1.
			\item \verb|dot|: for taking the dot product of two vectors of the same size.
			\item \verb|transpose|: for taking the transpose of a vector.
			\item \verb|linalg.inv|: for finding the inverse of a square matrix.
		\end{itemize}}
		\item{\verb|mse(X, y, w)|\\\textbf{Function implementation considerations:} This function finds the mean squared error introduced by the linear plane defined by
			\verb|w|. You can use the \verb|pred| function that is implemented for you to find the prediction by the classifier defined by \verb|w|.  Moreover, Useful functions in \verb|NumPy| for implementing this function are \verb|shape|, \verb|hstack|, \verb|ones|, and \verb|dot|.}
\end{itemize}
For this implementation, we also provide the test function \verb|subtestFn()|. This function loads a toy dataset,
runs your \verb|NumPy| implementation and return a message indicating whether your solution works when
\verb|X_train| is not a full-column rank matrix, \textit{i.e.}, the input features are not linearly independent.\\

\textbf{Answer the following question(s).} Write and save your answer in a separate \verb|PA1_qa.pdf| file. Remember
to submit this file together with your code.
\begin{enumerate}[label=\ref{part2.1}.\alph*)]
	\item When we input a singular matrix, the function \verb|linalg.inv| often returns an error message. In your
	\verb|fit_LinRegr(X_train, y_train)| implementation, is your input to the function \verb|linalg.inv| a
	singular matrix? Explain why. (2 marks)
	\item As you are using \verb|linalg.inv| for matrix inversion, report the output message when running the
	function \verb|subtestFn()|. We note that inputting a singular matrix to \verb|linalg.inv| sometimes does
	not yield an error due to numerical issue. (1 marks)
	\item Replace the function \verb|linalg.inv| with \verb|linalg.pinv|, you should get the model's weight and the
	``NO ERROR'' message after running the function \verb|subtestFn()|. Explain the difference between
	\verb|linalg.inv| and \verb|linalg.pinv|, and report the model's weight. (2 marks)
\end{enumerate}
The following is the mark breakdown for Part~\ref{part2.1}:
\begin{enumerate}[label=(\roman*)]
	\item Test file successfully runs the two implemented functions: 8 marks
	\item Outputs of all the functions are close to the expected output: 12 marks
	\item Code content is organized well and annotated with useful comments: 5 marks
	\item Questions are answered correctly: 5 marks
\end{enumerate}
\subsection{Linear Regressions Using \UseVerb{sci}} \label{part2.2}
In this part, you will use the \verb|scikit-learn| library to train the linear regression model. You will then
compare the performance of your implementation in~\ref{part2.1} with the one available in the \verb|scikit-learn|
library. You will implement one function in this part in the \verb|LinearRegressionImp.py| file. Specifically, you will be implementing the 
function which is detailed in the following. For more instructions and hints, see the comments in the \verb|LinearRegressionImp.py|
file.
\begin{itemize}
	\item{\verb|test_SciKit(X_train, X_test, y_train, y_test)|\\\textbf{Function implementation considerations:} This function will output the mean squared error on the test set, which is obtained from the \verb|mean_squared_error| function imported from \verb|sklearn.metrics| library to report the performance
		of the fitted \verb|LinearRegression| model using the linear regression algorithm available in the \verb|sklearn.linear_model|
		library.
		First, initiate an object of the \verb|LinearRegression| type. Next, run
		the fit function to train the model. Then, use the predict function to perform predictions
		using the trained algorithm. Finally, use the \verb|mean_squared_error| function to
		compute the mean squared error of the trained model.}
\end{itemize}
How close is the performance of your implementation in comparison to the existing modules in the
\verb|scikit-learn| library? Place your answer as a comment at the end of the code file.\\

The following is the mark breakdown for Part~\ref{part2.2}:
\begin{enumerate}[label=(\roman*)]
	\item Test file successfully runs implemented function: 6 marks
	\item Output is close to the expected output from the test file: 8 marks
	\item Code content is organized well and annotated with comments: 6 marks
\end{enumerate}
\section{Discussion}\label{disc}
Please answer the following short questions so we can improve future assignments.
\begin{enumerate}[label=\ref{disc}.\alph*)]
	\item How much time did you spend on each part of this assignment? (optional)
	\item Any additional feedback? (optional)
\end{enumerate}
\section{Turning It In}
You need to submit your version of the following files:
\begin{itemize}
	\item PerceptronImp.py
	\item LinearRegressionImp.py
	\item PA1\_qa.pdf that answer questions related to the implementations.
	\item The cover file (this file) with their name and student ID filled.
\end{itemize}
Please pack them into a single folder, compress into a .zip file and name it as PA1.zip.
\end{document}
